# Inspiration v2.0 â€” Build Plan

> **Version:** 2.0 (Knowledge Graphs Release)  
> **Last Updated:** 2026-01-16  
> **Status:** ğŸš€ In Progress (Iteration 1)  
> **Philosophy:** Ship incrementally, iterate based on user feedback

---

## TL;DR â€” What's New in v2.0

**Core Value Proposition:** **Longitudinal Intelligence via Knowledge Graphs**

| Feature | v1.0 | v2.0 |
|---------|------|------|
| **Semantic Search** | âœ… Lenny + User | âœ… Same |
| **Theme Explorer** | âœ… Pattern discovery | âœ… Enhanced |
| **Knowledge Graphs** | âŒ None | ğŸ†• **Lenny + User KGs** |
| **Entity Explorer** | âŒ None | ğŸ†• **Browse entities/relations** |
| **Cross-Source Insights** | âŒ None | ğŸ†• **User â†” Expert connections** |
| **Provenance Tracking** | âŒ None | ğŸ†• **Show sources** |
| **Confidence Scoring** | âŒ None | ğŸ†• **Filter by quality** |

---

## What Are Knowledge Graphs?

**Knowledge Graphs (KGs)** extract and connect **entities** (people, tools, concepts) and **relations** (how they interact) from text.

### Example: From Text to KG

**Input Text:**
> "We use the Circuit Breaker pattern to handle API failures. It's similar to rate limiting but more sophisticated."

**Extracted KG:**
- **Entities:** Circuit Breaker (pattern), API failures (problem), rate limiting (pattern)
- **Relations:** 
  - Circuit Breaker SOLVES API failures
  - Circuit Breaker SIMILAR_TO rate limiting

**User Value:**
- **Discover:** What tools/patterns have I discussed?
- **Connect:** How does my knowledge relate to expert insights?
- **Learn:** What have experts said about topics I care about?

---

## v2.0 Features

### 1. Lenny's Knowledge Graph (Expert Insights)

**Source:** 303 episodes from Lenny's Podcast ([ChatPRD/lennys-podcast-transcripts](https://github.com/ChatPRD/lennys-podcast-transcripts))

**Content:**
- **Entities:** 3,000-5,000 expert entities
  - People (guests, mentioned experts)
  - Tools (Figma, Next.js, Linear)
  - Concepts (Product-Market Fit, Growth Loops)
  - Patterns (Circuit Breaker, North Star Metric)
  - Problems (user churn, slow growth)
  - Strategies (retention tactics, growth strategies)
  - Projects (successful products, case studies)
  - Workflows (processes, methodologies)
  - Data Sources (metrics, analytics tools)

- **Relations:** 2,000-4,000 connections
  - SOLVES (tool â†’ problem)
  - ENABLES (tool â†’ capability)
  - USED_WITH (tool â†’ tool)
  - ALTERNATIVE_TO (tool â†’ tool)
  - PART_OF (component â†’ system)
  - REQUIRES (dependency)
  - IMPLEMENTS (pattern â†’ implementation)

**Quality:**
- Domain-agnostic filter (works for ANY topic, not just PM)
- Quality threshold: 0.35 (44% of chunks pass)
- Confidence scoring (0-1.0 for each entity)
- Provenance tracking (link to source episodes)
- Deduplicated ("Next.js" = "NextJS" merged)

**User Experience:**
1. **Entity Explorer:** Browse all expert entities
2. **Filter by Confidence:** Show only ğŸŸ¢ high-quality entities
3. **View Sources:** Click entity â†’ See which episodes mentioned it
4. **Explore Relations:** See how entities connect

---

### 2. User's Knowledge Graph (Personal Insights)

**Source:** User's Cursor + Claude Code chat history (local machine)

**Content:**
- **Entities:** Extracted from user's chat history
  - Tools user has discussed
  - Problems user is solving
  - Patterns user has explored
  - Concepts user is learning

- **Relations:** How entities connect in user's context

**Quality:**
- Same domain-agnostic filter as Lenny's
- Confidence scoring
- Incremental updates (only new messages)

**User Experience:**
1. **Personal Entity Explorer:** "What have I discussed?"
2. **Cross-Source Insights:** "What do experts say about topics I care about?"
3. **Knowledge Gaps:** "What expert topics haven't I explored yet?"

---

### 3. Pro Features (Built-In from Day 1)

#### ğŸŸ¢ Provenance/Evidence Tracking

**User Need:** "Where did this entity come from? Is AI making this up?"

**Solution:**
- Every entity links to source messages/episodes
- Click "ğŸ“ View Sources" â†’ See all mentions
- Verify authenticity, see context

**Example:**
```
Circuit Breaker â€” ğŸŸ¢ 92% confidence
ğŸ“ View Sources (5)

Sources:
1. ğŸ“º Lenny's Podcast â€” Julie Zhuo (Episode 234)
   "...we use Circuit Breaker pattern to handle API failures..."
   [View Full Transcript]

2. ğŸ’¬ Your Chat â€” 2026-01-10 (Your Workspace)
   "Should we implement Circuit Breaker for the API calls?"
   [View Full Chat]
```

**Impact:** Users trust data because they can verify it

---

#### ğŸŸ¢ Confidence Scoring

**User Need:** "Too many entities, some are garbage. Which ones matter?"

**Solution:**
- Score each entity 0-1.0 based on:
  - Mention count (more = higher)
  - Cross-source validation (user + expert)
  - Relation count (connected = more real)
  - Proper noun (capitalized)
  - Multi-word (specific)

**Tiers:**
- ğŸŸ¢ High (0.8-1.0): Multiple mentions, cross-validated, connected
- ğŸŸ¡ Medium (0.5-0.8): Reasonable confidence
- ğŸŸ  Low (0.3-0.5): Uncertain
- ğŸ”´ Very Low (0-0.3): Likely noise (hidden by default)

**Filter:**
```
Entity Explorer
[Filter] ğŸŸ¢ High Confidence Only

Results: 1,234 entities (down from 5,000)
Quality: Clean, trustworthy, actionable
```

**Impact:** Users see clean data, not overwhelmed by noise

---

#### ğŸŸ¢ Improved Deduplication

**User Need:** "Why are 'Next.js' and 'NextJS' separate entities? This looks broken."

**Solution:**
- Fuzzy matching: "Next.js" = "NextJS" = "next.js"
- Alias tracking: Canonical "Next.js" has aliases ["NextJS", "Next"]
- Levenshtein distance for near-matches

**Result:**
```
Before: 
- Next.js (15 mentions)
- NextJS (8 mentions)
- next.js (3 mentions)

After:
- Next.js (26 mentions)
  Aliases: NextJS, next.js
```

**Impact:** Professional-quality data, no obvious duplicates

---

## User Flows

### Flow 1: Explore Expert Knowledge

```
1. User opens Inspiration v2.0
2. Clicks "Entity Explorer" â†’ "Lenny's Knowledge"
3. Sets filter: ğŸŸ¢ High Confidence
4. Sees: "Circuit Breaker", "Product-Market Fit", "Next.js"
5. Clicks "Circuit Breaker"
6. Sees: 
   - Definition from expert episodes
   - 5 mentions across episodes
   - Related: API failures (SOLVES), rate limiting (SIMILAR_TO)
7. Clicks "ğŸ“ View Sources"
8. Sees: Episode 234 (Julie Zhuo), Episode 156 (Shreyas Doshi)
9. Clicks "View Full Transcript" â†’ Reads context
10. Learns: How experts use Circuit Breaker pattern
```

---

### Flow 2: Index Personal Knowledge

```
1. User clicks "SYNC Memory" button
2. Sees cost/time estimate:
   - ğŸ“Š 45,321 messages
   - ğŸ“¦ 8,234 high-quality chunks (18%)
   - ğŸ’° Estimated cost: $3.45
   - â±ï¸ Estimated time: 45 minutes
3. Clicks "Start Indexing"
4. Sees progress:
   - âœ… Processed: 3,700 / 8,234 (45%)
   - ğŸ‘¥ Entities: 127 created, 45 deduplicated
5. After completion:
   - âœ… 172 personal entities extracted
   - âœ… 89 relations discovered
   - âœ… 23 entities match expert knowledge (cross-validated!)
6. Explores personal Entity Explorer
7. Sees: Tools discussed, problems explored, patterns learned
```

---

### Flow 3: Cross-Source Insights

```
1. User has indexed personal chat history
2. Opens Entity Explorer â†’ "Cross-Source"
3. Sees entities mentioned by BOTH user and experts:
   - Next.js (ğŸŸ¢ 98% confidence)
     - You: 15 mentions
     - Experts: 23 mentions
   - Product-Market Fit (ğŸŸ¢ 95% confidence)
     - You: 8 mentions
     - Experts: 45 mentions
4. Clicks "Product-Market Fit"
5. Sees:
   - Your context: Struggling to find PMF for new feature
   - Expert insights: 7 episodes discuss PMF (Julie Zhuo, Shreyas Doshi, etc.)
6. Clicks "View Expert Insights"
7. Reads: How experts define and measure PMF
8. Applies: Insights to own product work
```

---

## Build Timeline

### âœ… Iteration 1: Lenny's Baseline + Pro Features (Week 1)

**Goal:** Create production-ready Lenny's KG baseline

#### Part A: Hardening (COMPLETE âœ…)

**Status:** âœ… COMPLETE (2026-01-16)  
**Time:** 8 hours (research + implementation)

**What We Built:**
1. **Domain-Agnostic Quality Filter**
   - Removed PM bias, works for ANY domain
   - Universal signals: named entities, problem+solution, comparisons
   - Threshold: 0.35 (77% filtered in production)
   - File: `engine/common/kg_quality_filter.py`

2. **Production Readiness (Phase 1)**
   - Circuit breaker for permanent API failures
   - Quality-aware fallback (Haiku â†’ GPT-4o, never GPT-3.5 for baseline)
   - Exception handling fixed (multiprocessing propagation)
   - Context validation to prevent typos
   - Files: `engine/common/llm.py`, `entity_extractor.py`, `index_lenny_kg_parallel.py`

3. **Provenance Tracking (Phase 2 - COMPLETE âœ…)**
   - Database migration: `kg_episode_metadata` table âœ…
   - Episode loader script: Parses 303 episode YAML frontmatter âœ…
   - API endpoint: `/api/kg/mention-sources` âœ…
   - Frontend integration: YouTube links in EntityExplorer âœ…
   - Files: 
     - `migrations/001_add_episode_metadata.sql`
     - `load_episode_metadata.py`
     - `src/app/api/kg/mention-sources/route.ts`
     - `src/components/EntityExplorer.tsx` (updated)

4. **Comprehensive CodeFix**
   - Reviewed 5 core files (~2,000 LOC)
   - Found: 0 quality-affecting bugs âœ…
   - All extraction logic verified correct

**Evidence:**
- All docs archived: `_archive/kg-hardening-2026-01-16/`
- Logged in: `BUILD_LOG.md` (2026-01-16 entry)
- Decisions in: `PIVOT_LOG.md` (3 key decisions)

---

#### Part B: Baseline Indexing (RUNNING ğŸŸ¢)

**Status:** ğŸŸ¢ RUNNING (high quality, stable)  
**Started:** 2026-01-16 18:42  
**Current:** 2026-01-16 19:47 (1h 5min elapsed)  
**Expected End:** ~11:50 PM (~4.1 hours remaining)

**Progress:**
- **Processed:** 9,870 / 48,507 chunks (20.3%)
- **Indexed:** 4,780 unique chunks (quality filter working âœ…)
- **Rate:** ~156 chunks/min (slowed due to more high-quality chunks)
- **Quality filter:** ~77% filtered (domain-agnostic working âœ…)

**Database Stats:**
- âœ… **Expert Entities:** 3,949 (target: 3,000-5,000) âœ… **On track!**
- âœ… **Total Mentions:** 13,681
- âœ… **Relations:** Being extracted (some JSON decode errors, but continuing)

**Specs:**
- 303 episodes, 50,815 total chunks
- Quality threshold: 0.35 (domain-agnostic)
- Model: Claude Haiku 4.5 (+ GPT-4o fallback if needed)
- Cost: ~$95 (budget unblocked)
- Workers: 4 parallel

**Output (Expected):**
- 3,000-5,000 expert entities
- 2,000-4,000 relations
- 15,000-25,000 mentions

**Monitoring:**
- Log: `/tmp/lenny_kg_baseline_20260116_181849.log`
- Error log: `/tmp/lenny_kg_errors.log` (empty âœ…)
- PID: 32927
- Status: `LENNY_KG_BUILD_STATUS.md`

---

#### Part C: Pro Features (COMPLETE âœ…)

**Status:** âœ… **ALL COMPLETE** (2026-01-16)

1. **Provenance Tracking** âœ…
   - Database migration âœ…
   - Episode loader script âœ…
   - API endpoint: `/api/kg/mention-sources` âœ…
   - Frontend: YouTube links in EntityExplorer âœ…
   - Files: `mention-sources/route.ts`, `EntityExplorer.tsx`

2. **Confidence Scoring** âœ…
   - Stored in database: `kg_entities.confidence` âœ…
   - UI filter dropdown (All / High / Medium / Low) âœ…
   - Confidence badges (ğŸŸ¢ ğŸŸ¡ ğŸŸ ) âœ…
   - Files: `entities/route.ts`, `EntityExplorer.tsx`

3. **Deduplication** âœ…
   - Multi-stage: exact + alias + embedding (0.85 threshold) âœ…
   - Working in production (79% merge rate validated) âœ…
   - File: `engine/common/entity_deduplicator.py`

**Next:** Load episode metadata â†’ Test â†’ Export â†’ Release (2026-01-17)

---

### â³ Iteration 2: User Chat Indexing (Week 2, 6-8 hours)

**Goal:** Let users build personal KG

**Features:**
1. **True Incremental Indexing** (3-4h)
   - Store last sync timestamp
   - Only process NEW messages
   - Fast subsequent syncs (<5 min)

2. **Cost/Time Estimator** (2h)
   - Pre-run warning: "500MB = $45, 6 hours"
   - Show chunk count, cost, time

3. **Progress UI** (1-2h)
   - Real-time progress bar
   - Entity counts, ETA

**Ship:** Users can index chat history

---

### â³ Iteration 3: Better UX (Week 3, 3-4 hours)

**Goal:** Make indexing less scary

**Features:**
1. **User-Friendly Errors** (2-3h)
   - Transform stack traces
   - Show: "â¸ï¸ Paused due to rate limits. Retrying..."

2. **Better Progress Messages** (1h)
   - Friendly status updates
   - Clear feedback

**Ship:** Polished user experience

---

### ğŸ’­ Iteration 4: Background Processing (Month 2, 10-12 hours)

**Goal:** Let users close browser during indexing

**Only if users complain:**
- "Can't close laptop for 2 hours"
- "Browser crashed mid-indexing"

**Features:**
- Job queue (Inngest/BullMQ)
- Status polling API
- Pause/resume

**Ship:** If user demand exists

---

## Technical Architecture

### Database Schema

```sql
-- Entities (people, tools, concepts)
CREATE TABLE kg_entities (
  id TEXT PRIMARY KEY,
  canonical_name TEXT NOT NULL,
  entity_type TEXT NOT NULL, -- tool, concept, person, pattern, etc.
  mention_count INT DEFAULT 0,
  source_type TEXT NOT NULL, -- 'user', 'expert', 'both'
  source_breakdown JSONB, -- {'user': 5, 'expert': 10}
  confidence FLOAT DEFAULT 0.5, -- 0-1.0 confidence score
  aliases TEXT[], -- ['NextJS', 'next.js']
  embedding VECTOR(1536), -- For similarity search
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Relations (how entities connect)
CREATE TABLE kg_relations (
  id TEXT PRIMARY KEY,
  source_entity_id TEXT REFERENCES kg_entities(id),
  target_entity_id TEXT REFERENCES kg_entities(id),
  relation_type TEXT NOT NULL, -- SOLVES, ENABLES, USED_WITH, etc.
  confidence FLOAT, -- Optional confidence
  evidence_snippet TEXT, -- Context for relation
  source_message_id TEXT -- Where this relation came from
);

-- Mentions (provenance/evidence)
CREATE TABLE kg_entity_mentions (
  id TEXT PRIMARY KEY,
  entity_id TEXT REFERENCES kg_entities(id),
  message_id TEXT NOT NULL, -- 'lenny-{episode}-{chunk}' or 'user-{chat}-{chunk}'
  context_snippet TEXT, -- Surrounding text
  message_timestamp BIGINT -- Unix timestamp (ms)
);
```

### Indexing Pipeline

```
Raw Text (Lenny transcripts OR user chat)
    â†“
Chunking (200-300 tokens per chunk)
    â†“
Quality Filter (domain-agnostic, 0.35 threshold)
    â†“ (only 44% pass)
Entity Extraction (Claude Haiku 4.5)
    â†“
Post-Filter Validation (reject generic entities)
    â†“
Fuzzy Deduplication (merge "Next.js" = "NextJS")
    â†“
Confidence Scoring (calculate 0-1.0 score)
    â†“
Relation Extraction (optional, for connections)
    â†“
Save to Supabase KG tables
```

### Quality Filter (Domain-Agnostic)

**Signals (universal, works for ANY domain):**
1. **Named entities** (30%): Capitalized proper nouns
2. **Problem + Solution** (35%): Describes both
3. **Comparative analysis** (20%): "X vs Y", "pros/cons"
4. **Metrics/Data** (15%): "50%", "10x", "$100M"
5. **Technical terms** (15%): camelCase, kebab-case
6. **Framework indicators** (10%): "RICE framework", "Design Thinking"

**Threshold:** 0.35 (44% pass rate for Lenny's podcast)

**Why domain-agnostic:** Works for PM, engineering, design, marketing, AI/ML, psychology, leadership, etc.

---

## Success Metrics

### Iteration 1 (Lenny's Baseline)

- âœ… Baseline posted to GitHub
- âœ… 3,000-5,000 expert entities
- âœ… Quality passes manual review
- âœ… Pro features integrated
- âœ… Users can download and import

### Iteration 2 (User Indexing)

- âœ… 20%+ of users index their chat
- âœ… Incremental updates < 5 minutes
- âœ… Cost warnings shown
- âœ… No major complaints

### Iteration 3 (UX)

- âœ… <5% error-related support requests
- âœ… Users understand progress
- âœ… No scary technical errors

### Overall v2.0

- âœ… 40%+ of users explore Entity Explorer
- âœ… 20%+ of users index personal chat
- âœ… 10%+ of users find cross-source insights valuable
- âœ… Entity Explorer NPS > 8/10

---

## Cost & Performance

### Lenny's Baseline (One-Time)

| Metric | Value |
|--------|-------|
| **Chunks** | 50,815 total |
| **Quality Pass** | 22,404 (44%) |
| **Cost** | $94.10 |
| **Time** | 18.9 hours (4 workers) |
| **Rate** | 19.8 chunks/min |

**User Cost:** $0 (download pre-built baseline)

### User Chat Indexing (Per User)

| Chat Size | Chunks | Cost | Time |
|-----------|--------|------|------|
| Small (10MB) | ~2,000 | $0.40 | 10 min |
| Medium (100MB) | ~20,000 | $4.00 | 1.5 hours |
| Large (500MB) | ~100,000 | $20.00 | 8 hours |
| Huge (1GB+) | ~200,000+ | $40.00+ | 16+ hours |

**Incremental updates:** $0.10 - $2.00 (only new messages)

---

## Risks & Mitigation

| Risk | Mitigation |
|------|------------|
| **Baseline quality poor** | Manual review before release |
| **Cost too high for users** | Show warning, let users decide |
| **Indexing too slow** | Incremental updates, background processing |
| **Entities too noisy** | Confidence filter, raise threshold |
| **Users don't trust data** | Provenance tracking (show sources) |
| **Duplicates persist** | Improved deduplication, manual merge tool |

---

## What's NOT in v2.0

âŒ **Real-time extraction during chat** â€” Too slow  
âŒ **Graph database (Neo4j)** â€” PostgreSQL sufficient  
âŒ **Multi-hop inference** â€” Too complex  
âŒ **Entity hierarchies** â€” Wait for user demand  
âŒ **External linking (Wikipedia)** â€” Low ROI  
âŒ **Custom entity types** â€” 9 types cover 95% of cases

---

## Rollout Plan

### Phase 1: Internal Testing (Week 1-2)

- Build and test Lenny's baseline
- Manual quality review
- Test on own chat history

### Phase 2: Beta Users (Week 3-4)

- Share baseline with 5-10 beta users
- Collect feedback
- Iterate on UX

### Phase 3: Public Launch (Week 5)

- Announce v2.0
- Post baseline to GitHub
- Update documentation
- Monitor adoption

### Phase 4: Iterate (Month 2+)

- Add features based on feedback
- Improve quality filters
- Optimize performance

---

## Documentation

### For Users

- **KG_USER_GUIDE.md** â€” How to use KG features
- **README.md** â€” Updated with v2.0 features
- **GitHub Release Notes** â€” Baseline download instructions

### For Developers

- **INSPIRATION_V2_PLAN.md** â€” This document
- **ARCHITECTURE.md** â€” Updated with KG architecture
- **engine/KG_QUALITY_DEFINITION.md** â€” Quality filter details

### Operational

- **LENNY_KG_BUILD_STATUS.md** â€” Current baseline build status
- **monitor-kg-build.sh** â€” Monitoring script
- **check_kg_status_simple.py** â€” Database status check

---

## Next Steps (Right Now)

### âœ… Completed Today (2026-01-16)

- âœ… Domain-agnostic quality filter (removed PM bias)
- âœ… Production hardening (circuit breaker, fallback, exception handling)
- âœ… Comprehensive CodeFix (0 quality bugs found)
- âœ… Provenance foundation (migration + loader)
- âœ… Confidence scoring (already built, just needs UI)
- âœ… Deduplication (already built, working in production)
- âœ… Budget issue resolved (user-set limit raised)
- âœ… Baseline indexing restarted (18:18, running smoothly)
- âœ… Documentation consolidated (this doc + canonical docs)

**Time Invested:** ~8 hours (hardening + research)  
**Value:** Production-grade KG system, not just a one-off script

---

### ğŸ”„ In Progress (2026-01-16 Evening)

**Baseline Indexing:**
- Status: Running (PID: 32927)
- Progress: ~0.8% (410 / 48,669 chunks processed so far)
- Rate: ~920 chunks/min
- ETA: ~19:10 (52 minutes remaining)
- Quality: 77% filtered (domain-agnostic working)

**Monitoring:**
```bash
# Real-time
tail -f /tmp/lenny_kg_baseline_20260116_181849.log

# Quick check
tail -20 /tmp/lenny_kg_baseline_20260116_181849.log
```

---

### Tomorrow (2026-01-17)

**Morning (After indexing completes ~11:50 PM tonight):**
- [ ] Load episode metadata (`load_episode_metadata.py`, 10 min)
- [ ] Verify baseline quality (spot check entities, 30 min)
- [ ] Test provenance (YouTube links work, 15 min)
- [ ] Test confidence filter (high/medium/low, 15 min)

**Afternoon:**
- [ ] Export baseline to JSON + SQL (`export_lenny_kg_baseline.py`, 30 min)
- [ ] Create GitHub Release (upload files, write notes, 15 min)
- [ ] Update README.md with v2.0 features (30 min)
- [ ] ğŸ‰ **Ship Lenny's Baseline v1.0!**

**Evening:**
- [ ] Plan Iteration 2 (User Chat Indexing)
- [ ] Rest and celebrate! ğŸ‰

**Total Time:** ~2.5 hours (much faster than originally estimated!)

---

## Contact & Support

**Questions?** Check:
1. This plan (you're reading it!)
2. `LENNY_KG_BUILD_STATUS.md` for current build status
3. `KG_USER_GUIDE.md` for user-facing docs
4. GitHub Issues for known problems

---

**Version:** v2.0  
**Last Updated:** 2026-01-16  
**Status:** ğŸš€ Iteration 1 in progress  
**Next Review:** 2026-01-18 (after baseline ships)
